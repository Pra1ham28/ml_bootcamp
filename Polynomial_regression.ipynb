{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TYbIb5u5DTOZ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tE-bR35ED9wZ"},"outputs":[],"source":["class Polynomial_Regression():\n","  #Adding polynomial features\n","  def Add_Polynomial_Features(self,X,degrees):\n","    self.A=X\n","    X1=np.copy(self.A)\n","    for j in range(2,degrees+1):\n","      n=X1.shape[1]\n","      self.add(j,n,X1)\n","    return self.A\n","\n","  #Recursion function that helps to add the features\n","  def add(self,sum,no_elements,X1,i=0,arr=None):\n","    if not arr:\n","        arr =[0]*no_elements  \n","    if sum<0:\n","        return\n","    if i==no_elements:\n","        if sum==0:\n","          M=X1**arr\n","          p=np.ones((X1.shape[0],1))\n","          for k in range(X1.shape[1]):\n","            p*=(M[:,k].reshape(-1,1))\n","            p=p.reshape(-1,1)\n","          self.A=np.append(self.A,p,axis=1)\n","        return\n","    for val in range(0,sum+1):\n","        arr[i] = val\n","        self.add(sum-val,no_elements,X1,i+1,arr)\n","  \n","  def train_dev_split(self,X,Y,train_size):\n","    m_=int(train_size*X.shape[0])\n","    X_train=X[:m_,:]\n","    X_dev=X[m_:,:]\n","    Y_train=Y[:m_]\n","    Y_dev=Y[m_:] \n","    return X_train,Y_train,X_dev,Y_dev\n","\n","  #Z score normalization\n","  def Z_score_standardize(self,X,X_train_):\n","    Mean=np.mean(X_train_,axis=0)\n","    std=np.std(X_train_,axis=0)\n","    std[std==0]=1\n","    return (X-Mean)/std\n","\n","  def min_max_normalize(self,X,X_train_):\n","    Min=np.min(X_train_,axis=0)\n","    Max=np.max(X_train_,axis=0)\n","    Range=Max-Min\n","    Range[Range==0]=1\n","    return (X-Min)/Range\n","\n","  \n","  #Batch gradient descent\n","  def Batch_GD(self,X_train,Y_train,iterations=7,learning_rate=0.6,L2_regularization_term=0,Exp_learning_rate_decay=None,Feature_Scaling=\"Z_score_standardization\",validation=False,X_dev=np.array([]),Y_dev=np.array([])): \n","    alpha=learning_rate\n","    alpha1=alpha\n","    lamda=L2_regularization_term\n","    self.iterations=iterations\n","    self.validation=validation\n","    self.Y_train=Y_train.reshape(-1,1)\n","    self.X_train_=np.copy(X_train)  \n","    if Feature_Scaling==\"Z_score_standardization\":\n","      self.X_train_n=self.Z_score_standardize(X_train,self.X_train_)\n","    elif Feature_Scaling==\"min_max_normalization\":\n","      self.X_train_n=self.min_max_normalize(X_train,self.X_train_)\n","    else:\n","      self.X_train_n=X_train\n","    m_train,n_train=self.X_train_n.shape  \n","    self.w=np.random.randn(n_train,1)  \n","    self.b=np.random.randn()  \n","    self.J_train_list=[] \n","    self.R2_train_list=[]\n","    if self.validation:\n","      if X_dev.size>0 and Y_dev.size>0:\n","        self.X_dev_=np.copy(X_dev)\n","        self.J_dev_list=[]\n","        self.R2_dev_list=[]\n","        self.Y_dev=Y_dev.reshape(-1,1)\n","        if Feature_Scaling==\"Z_score_standardization\":\n","          self.X_dev_n=self.Z_score_standardize(X_dev,self.X_train_)\n","        elif Feature_Scaling==\"min_max_normalization\":\n","          self.X_dev_n=self.min_max_normalize(X_dev,self.X_train_)\n","        else:\n","          self.X_dev_n=X_dev\n","      else:\n","        print(\"Please give dev data in function call\" )\n","        return \n","\n","    for i in range(self.iterations):\n","      Y_pred_train=self.predict(self.X_train_n)\n","      self.J_train_list.append(self.MSE(self.Y_train,Y_pred_train))\n","      self.R2_train_list.append(self.R2(self.Y_train,Y_pred_train))\n","      if self.validation:\n","        Y_pred_dev=self.predict(self.X_dev_n)\n","        self.J_dev_list.append(self.MSE(self.Y_dev,Y_pred_dev))\n","        self.R2_dev_list.append(self.R2(self.Y_dev,Y_pred_dev))\n","      dJ_dw=(1/m_train)*(self.X_train_n.T@(Y_pred_train-self.Y_train))+((lamda/m_train)*self.w)\n","      dJ_db=(1/m_train)*(np.sum(Y_pred_train-self.Y_train))\n","      self.w -= alpha*dJ_dw\n","      self.b -= alpha*dJ_db     \n","      if Exp_learning_rate_decay:\n","        alpha=((Exp_learning_rate_decay)**i)*alpha1\n","\n","    Y_pred_train=self.predict(self.X_train_n)\n","    self.J_train_list.append(self.MSE(self.Y_train,Y_pred_train))\n","    self.R2_train_list.append(self.R2(self.Y_train,Y_pred_train))\n","    if self.validation:\n","      Y_pred_dev=self.predict(self.X_dev_n)\n","      self.J_dev_list.append(self.MSE(self.Y_dev,Y_pred_dev))\n","      self.R2_dev_list.append(self.R2(self.Y_dev,Y_pred_dev))\n","  \n","  def mini_batch_GD(self,X_train,Y_train,epochs=7,learning_rate=0.6,L2_regularization_term=0,Exp_learning_rate_decay=None,mini_batch_size=100,Feature_Scaling=\"Z_score_standardization\",validation=False,X_dev=np.array([]),Y_dev=np.array([])):\n","    self.mini_batch_size=mini_batch_size\n","    self.alpha=learning_rate\n","    alpha1=self.alpha\n","    self.lamda=L2_regularization_term\n","    self.iterations=epochs\n","    self.validation=validation\n","    self.Y_train=Y_train.reshape(-1,1)\n","    self.X_train_=np.copy(X_train)  \n","    self.n=X_train.shape[1]\n","    self.mini_batch_size=mini_batch_size\n","    if Feature_Scaling==\"Z_score_standardization\":\n","      self.X_train_n=self.Z_score_standardize(X_train,self.X_train_)\n","    elif Feature_Scaling==\"min_max_normalization\":\n","      self.X_train_n=self.min_max_normalize(X_train,self.X_train_)\n","    else:\n","      self.X_train_n=X_train\n","    m_train,n_train=self.X_train_n.shape  \n","    self.w=np.random.randn(n_train,1)  \n","    self.b=np.random.randn()  \n","    self.J_train_list=[] \n","    self.R2_train_list=[]\n","    if self.validation:\n","      if X_dev.size>0 and Y_dev.size>0:\n","        self.X_dev_=np.copy(X_dev)\n","        self.J_dev_list=[]\n","        self.R2_dev_list=[]\n","        self.Y_dev=Y_dev.reshape(-1,1)\n","        if Feature_Scaling==\"Z_score_standardization\":\n","          self.X_dev_n=self.Z_score_standardize(X_dev,self.X_train_)\n","        elif Feature_Scaling==\"min_max_normalization\":\n","          self.X_dev_n=self.min_max_normalize(X_dev,self.X_train_)\n","        else:\n","          self.X_dev_n=X_dev\n","      else:\n","        print(\"Please give dev data in function call\" )\n","        return\n","    train_data=np.append(self.X_train_n,self.Y_train,axis=1)\n","\n","    for i in range(epochs):\n","      Y_pred_train=self.predict(self.X_train_n)\n","      self.J_train_list.append(self.MSE(self.Y_train,Y_pred_train))\n","      self.R2_train_list.append(self.R2(self.Y_train,Y_pred_train))\n","      if self.validation:\n","        Y_pred_dev=self.predict(self.X_dev_n)\n","        self.J_dev_list.append(self.MSE(self.Y_dev,Y_pred_dev))\n","        self.R2_dev_list.append(self.R2(self.Y_dev,Y_pred_dev))\n","      np.random.shuffle(train_data)\n","      mini_batch_list=[train_data[k:k+mini_batch_size,:] for k in range(0,m_train,mini_batch_size)]\n","      for mini_batch in mini_batch_list:\n","        self.update(mini_batch)\n","        \n","    if Exp_learning_rate_decay:\n","      self.alpha=(Exp_learning_rate_decay**i)*alpha1\n","      \n","    Y_pred_train=self.predict(self.X_train_n)\n","    self.J_train_list.append(self.MSE(self.Y_train,Y_pred_train))\n","    self.R2_train_list.append(self.R2(self.Y_train,Y_pred_train))\n","    if self.validation:\n","      Y_pred_dev=self.predict(self.X_dev_n)\n","      self.J_dev_list.append(self.MSE(self.Y_dev,Y_pred_dev))\n","      self.R2_dev_list.append(self.R2(self.Y_dev,Y_pred_dev))\n","\n","  def update(self,mini_batch):\n","    x=mini_batch[:,:self.n]\n","    y=mini_batch[:,self.n:]\n","    y_pred=self.predict(x)\n","    dw=(1/self.mini_batch_size)*((x.T)@(y_pred-y))+((self.lamda/self.mini_batch_size)*self.w)\n","    db=(1/self.mini_batch_size)*(np.sum(y_pred-y))\n","    self.w-=(self.alpha*dw)\n","    self.b-=(self.alpha*db)  \n","\n","  #Printing some results   \n","  def Results(self,MSE_learning_curve=True,R2_learning_curve=True,Single_feature_vs_label=True,Table_showing_predicted_vs_actual=True):\n","    li=np.arange(0,self.iterations+1)\n","    if MSE_learning_curve:\n","      print(\"Final MSE of training data is: \",self.J_train_list[-1],\"\\n\")\n","      if self.validation:\n","        print(\"Final MSE of dev data is: \",self.J_dev_list[-1],\"\\n\")\n","      plt.plot(li,self.J_train_list,color=\"blue\",label=\"Training Cost\")\n","      if self.validation:\n","        plt.plot(li,self.J_dev_list,color=\"Red\",label=\"Dev cost\")\n","      plt.xlabel(\"Iterations\")\n","      plt.ylabel(\"Cost\")\n","      plt.title(\"Cost vs Iterations curve\")\n","      plt.legend()\n","      plt.show()\n","      print(\"\\n\")\n","   \n","    if R2_learning_curve:\n","      print(\"Final R2 of training data is: \",self.R2_train_list[-1])\n","      print(\"\\n\")\n","      if self.validation:\n","        print(\"Final R2 of dev data is: \",self.R2_dev_list[-1])\n","        print(\"\\n\")\n","      plt.plot(li,self.R2_train_list,color=\"blue\",label=\"Train\")\n","      if self.validation:\n","        plt.plot(li,self.R2_dev_list,color=\"Red\",label=\"Dev\")\n","      plt.xlabel(\"Iterations\")\n","      plt.ylabel(\"R2\")\n","      plt.title(\"R2 vs Iterations curve\")\n","      plt.legend()\n","      plt.show()\n","      print(\"\\n\")\n","    \n","    if Single_feature_vs_label:\n","      plt.scatter(self.X_train_[:20,0],self.predict(self.X_train_n)[:20,:],color=\"blue\",label=\"Predicted\")\n","      plt.scatter(self.X_train_[:20,0],self.Y_train[:20,:],color=\"red\",label=\"Actual\")\n","      plt.xlabel(\"Iterations\")\n","      plt.ylabel(\"Label\")\n","      plt.title(\"Actual and predicted value of training set vs a single label for first 20 examples\")\n","      plt.legend()\n","      plt.show()\n","      print(\"\\n\")\n","\n","      if self.validation:\n","        plt.scatter(self.X_dev_[:20,0],self.predict(self.X_dev_n)[:20,:],color=\"blue\",label=\"Predicted\")\n","        plt.scatter(self.X_dev_[:20,0],self.Y_dev[:20,:],color=\"red\",label=\"Actual\")\n","        plt.xlabel(\"Iterations\")\n","        plt.ylabel(\"Label\")\n","        plt.title(\"Actual and predicted value of dev set vs a single label for first 20 examples\")\n","        plt.legend()\n","        plt.show()\n","        print(\"\\n\")\n","\n","    if Table_showing_predicted_vs_actual:\n","      train_table=np.append(self.Y_train[:20,:],self.predict(self.X_train_n)[:20,:],axis=1)\n","      df=pd.DataFrame(train_table,columns=[\"Actual\",\"Predicted\"])\n","      print(\"A table showing predicted labels and actual label for the first 20 examples of training data: \")\n","      print(df)\n","      print(\"\\n\")\n","\n","      if self.validation:\n","        train_table=np.append(self.Y_dev[:20,:],self.predict(self.X_dev_n)[:20,:],axis=1)\n","        df=pd.DataFrame(train_table,columns=[\"Actual\",\"Predicted\"])\n","        print(\"A table showing predicted labels and actual label for the first 20 examples of dev data: \")\n","        print(df)\n","\n","\n","    \n","  #predicting values\n","  def predict(self,X):\n","    return (X@self.w+self.b)\n","\n","  #Calculation mean squared errors\n","  def MSE(self,Y,Y_pred):\n","    Y=Y.reshape(-1,1)\n","    Y_pred=Y_pred.reshape(-1,1)\n","    return (1/(2*Y.shape[0]))*(np.sum(np.square(Y_pred-Y)))    \n","\n","  #R2 calculation\n","  def R2(self,Y,Y_pred):\n","    Y=Y.reshape(-1,1)\n","    Y_pred=Y_pred.reshape(-1,1)\n","    R2_calc=1-((self.MSE(Y,Y_pred)*2*Y.shape[0])/np.sum(np.square(Y_pred-Y.mean())))\n","    return R2_calc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDMJOX8VSmzh"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOG8M8+b2qFHPeFvRwFwHtL","mount_file_id":"1Lh7Dx0MCwO2ujYZIg4QLiSUvpvLGVzCP","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
